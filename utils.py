# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f_gWhHibpUXe_i2PQWKtQdtPuaBR9bLw
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.animation as animation
from sklearn.metrics import confusion_matrix
from tensorflow.image import resize
from tensorflow import convert_to_tensor
import itertools
from glob import glob


def im2col(input_data, filter_h, filter_w, stride=1, pad=0, xp=np):
    """
    Rearranges image blocks into columns.
    Input:
      - input_data: shape (N, C, H, W)
      - filter_h, filter_w: filter height and width
      - stride: stride for the convolution
      - pad: amount of zero-padding
      - xp: either np (CPU) or cp (GPU)
    Returns:
      - col: 2D array of shape (N*out_h*out_w, C*filter_h*filter_w)
    """
    N, C, H, W = input_data.shape

    # Determine padding values
    if isinstance(pad, int):
        pad_top = pad
        pad_bottom = pad
        pad_left = pad
        pad_right = pad
    else:
        # Expect pad to be ((pad_top, pad_bottom), (pad_left, pad_right))
        (pad_top, pad_bottom), (pad_left, pad_right) = pad

    # Pad the input
    input_padded = xp.pad(input_data, ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')

    # Compute output dimensions
    out_h = (H + pad_top + pad_bottom - filter_h) // stride + 1
    out_w = (W + pad_left + pad_right - filter_w) // stride + 1

    # Get strides for the padded array
    s0, s1, s2, s3 = input_padded.strides

    # Build shape and strides for as_strided
    shape = (N, C, out_h, out_w, filter_h, filter_w)
    strides = (s0, s1, s2 * stride, s3 * stride, s2, s3)
    cols = xp.lib.stride_tricks.as_strided(input_padded, shape=shape, strides=strides)

    # Rearrange dimensions so that each patch becomes a row
    cols = cols.transpose(0, 2, 3, 1, 4, 5).reshape(N * out_h * out_w, -1)
    return cols


def col2im(cols, input_shape, filter_h, filter_w, stride=1, pad=0, xp=np):
    """
    Converts column representation back into image blocks.
    Input:
      - col: 2D array from im2col with shape (N*out_h*out_w, C*filter_h*filter_w)
      - input_shape: shape (N, C, H, W) of the original input data
      - filter_h, filter_w: filter dimensions
      - stride, pad: convolution parameters. If pad is an int, symmetric padding is assumed.
                   If pad is a tuple of tuples, it should be ((pad_top, pad_bottom), (pad_left, pad_right)).
      - xp: either np or cp
    Returns:
      - An array with shape (N, C, H, W)
    """
    N, C, H, W = input_shape

    # Determine padding values
    if isinstance(pad, int):
        pad_top = pad
        pad_bottom = pad
        pad_left = pad
        pad_right = pad
    else:
        (pad_top, pad_bottom), (pad_left, pad_right) = pad

    # Compute output dimensions from im2col
    out_h = (H + pad_top + pad_bottom - filter_h) // stride + 1
    out_w = (W + pad_left + pad_right - filter_w) // stride + 1

    # Reshape cols to (N, out_h, out_w, C, filter_h, filter_w)
    cols_reshaped = cols.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)

    # Prepare an output array with padding
    H_padded = H + pad_top + pad_bottom
    W_padded = W + pad_left + pad_right
    img_padded = xp.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)

    # Instead of looping over the entire image, we only loop over the filter dimensions.
    for y in range(filter_h):
        y_end = y + stride * out_h
        for x in range(filter_w):
            # Accumulate the values from cols_reshaped into the appropriate region of img_padded.
            img_padded[:, :, y:y_end:stride, x:x + stride * out_w] += cols_reshaped[:, :, y, x, :, :]

    # Remove padding and return the original image dimensions.
    return img_padded[:, :, pad_top:H_padded - pad_bottom, pad_left:W_padded - pad_right]


# store functions used for processing data

def train_test_split(x, y, split=0.2):
    """
    returns x and y data split into training and testing sets according to split percentage passed
    Input:
        x: input data
        y: output data
    Return:
        x_train, y_train, x_test, y_test
    """
    
    split_index = int(np.floor(len(y)*split))
    x_train = x[split_index:]
    y_train = y[split_index:]
    x_test = x[:split_index]
    y_test = y[:split_index]
    
    return x_train, y_train, x_test, y_test

def build_metric_figure(layers):
    fig = plt.figure(tight_layout=True)
    grid = fig.add_gridspec(1,3)
    wb_grid = grid[0,0:2].subgridspec(nrows=int(np.ceil(len(layers)/2)), ncols=2)
    metric_grid = grid[0,2].subgridspec(3,1)

    for index, l in enumerate(layers):
        subgrid = wb_grid[int(np.floor(index/2)),index%2].subgridspec(3,1)
        plot1 = fig.add_subplot(subgrid[0:2,0])
        plot1.axes.yaxis.set_ticks(np.arange(l.weights.shape[0]))
        plot1.axes.xaxis.set_visible(False)
        plot1.grid(False)
        plot1.set_title(f'Layer {index}')

        plot2 = fig.add_subplot(subgrid[2,0], sharex=plot1)
        plot2.axes.yaxis.set_visible(False)
        plot2.axes.xaxis.set_ticks(np.arange(l.weights.shape[1]))
        plot2.grid(False)      

    plot_loss = fig.add_subplot(metric_grid[0,0])
    plot_loss.axes.xaxis.set_visible(False)
    plot_loss.set_title('Loss')
    plot_loss.legend()

    plot_accuracy = fig.add_subplot(metric_grid[1,0])
    plot_accuracy.axes.xaxis.set_visible(False)
    plot_accuracy.set_title('Accuracy')
    plot_accuracy.legend()

    plot_learning_rate = fig.add_subplot(metric_grid[2,0])
    plot_learning_rate.set_title('Learning Rate')
    
    return fig

# def animate(network, metrics, plot1, plot2, plot_loss, plot_accuracy, plot_learning_rate):
#     plt.cla()
    
#     for l in network.layers:
#         plot1.imshow(l.weights, cmap="seismic", aspect='auto')
#         plot2.imshow(np.expand_dims(l.bias, axis=1).T, cmap="seismic", aspect='auto')
        
#     # plot metric data
#     # plot loss    
#     # check if total loss exists in metric data (means network applies regularization)
#     if 'Total Loss' in network.metric_data:
#         plot_loss.plot(metrics['Total Loss'][:,0], label='total train', color='red', lw=1)
#         plot_loss.plot(metrics['Total Loss'][:,1], label='total validation', color='red', lw=1, alpha=0.5)
#         # plot regularizations if exist
#         if 'L2 Regularization' in network.metric_data:
#             plot_loss.plot(metrics['L2 Regularization'][:,0], label='L2 train', color='orange', lw=1)
#             plot_loss.plot(metrics['L2 Regularization'][:,1], label='L2 validation', color='orange', lw=1, alpha=0.5)
#         if 'L1 Regularization' in network.metric_data:
#             plot_loss.plot(metrics['L1 Regularization'][:,0], label='L1 train', color='purple', lw=1)
#             plot_loss.plot(metrics['L1 Regularization'][:,1], label='L1 validation', color='purple', lw=1, alpha=0.5)
#     plot_loss.plot(metrics['Sparse CXE'][:,0], label='loss train', color='blue', lw=1)
#     plot_loss.plot(metrics['Sparse CXE'][:,1], label='loss validation', color='blue', lw=1, alpha=0.5)
    
#     # plot accuracy
#     plot_accuracy.plot(metrics['Accuracy'][:,0], label='train', color='green', linewidth=1)
#     plot_accuracy.plot(metrics['Accuracy'][:,1], label='validation', color='green', alpha=0.3, linewidth=1)
    
#     # plot learning rate
#     plot_learning_rate.plot(metrics['Learning Rate'][:,0], label='train', color='red', linewidth=1)

def get_confusion_matrix(data:tuple, model:"Neural_Network"):
    """
    returns a confusion matrix generated from predictions made on images passed through an image data generator

    INPUTS
    data: tuple, tuple of (x,y)
    model: Neural_Network, model used to make predictions on images

    RETURNS
    cm: confusion matrix
    """
    print('Generating Confusion Matrix')
    # Unpack data tuple
    x,targets = data
    predictions = model.predict(x)
    predictions = model._xp.argmax(predictions, axis=1)
    # If device = GPU, convert arrays to NumPy using .get()
    if hasattr(predictions, "get"):
        predictions = predictions.get()
    if hasattr(targets, "get"):
        targets = targets.get()
    # targets = model._xp.argmax(y, axis=1)
    cm = confusion_matrix(targets, predictions)
    return cm

def plot_confusion_matrix(confusion_matrix, classes, normalize = False, title = 'Confusion Matrix', cmap = plt.cm.Blues):
    # Convert classes to a sequence by using range
    classes = np.arange(classes)
    if normalize:
        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]
        print('Normalized Confusion Matrix')
    else:
        print('Confusion Matrix, wihtout normalization')
    print(confusion_matrix)

    plt.figure(figsize=(15,15))
    plt.imshow(confusion_matrix, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = classes
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = confusion_matrix.max() / 2.
    for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):
        plt.text(j, i, format(confusion_matrix[i, j], fmt),
                 horizontalalignment='center',
                 color='white' if confusion_matrix[i, j] > thresh else 'black')
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

def get_accuracy_from_confusion_matrix(confusion_matrix):
    return confusion_matrix.trace() / confusion_matrix.sum()

def to_tf_tensor(x, model):
    # Convert x to a TensorFlow tensor
    # If using GPU (i.e. x is a cupy array), convert to a numpy array first.
    if model._device == "GPU":
        x_np = model._xp.asnumpy(x)
    else:
        x_np = x
    return convert_to_tensor(x_np)

def from_tf_tensor(x, model):
    # Convert a TensorFlow tensor back to the model's array type (numpy or cupy)
    x_np = x.numpy()
    if model._device == "GPU":
        return model._xp.asarray(x_np)
    else:
        return x_np