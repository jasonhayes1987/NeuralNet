# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f_gWhHibpUXe_i2PQWKtQdtPuaBR9bLw
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.animation as animation
from sklearn.metrics import confusion_matrix
from tensorflow.image import resize
from tensorflow import convert_to_tensor
import itertools
from glob import glob


def im2col(input_data, filter_h, filter_w, stride=1, pad=0, xp=np):
    """
    Rearranges image blocks into columns.
    Input:
      - input_data: shape (N, C, H, W)
      - filter_h, filter_w: filter height and width
      - stride: stride for the convolution
      - pad: amount of zero-padding
      - xp: either np (CPU) or cp (GPU)
    Returns:
      - col: 2D array of shape (N*out_h*out_w, C*filter_h*filter_w)
    """
    N, C, H, W = input_data.shape

    # Determine padding values
    if isinstance(pad, int):
        pad_top = pad
        pad_bottom = pad
        pad_left = pad
        pad_right = pad
    else:
        # Expect pad to be ((pad_top, pad_bottom), (pad_left, pad_right))
        (pad_top, pad_bottom), (pad_left, pad_right) = pad

    # Pad the input
    input_padded = xp.pad(input_data, ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')

    # Compute output dimensions
    out_h = (H + pad_top + pad_bottom - filter_h) // stride + 1
    out_w = (W + pad_left + pad_right - filter_w) // stride + 1

    # Get strides for the padded array
    s0, s1, s2, s3 = input_padded.strides

    # Build shape and strides for as_strided
    shape = (N, C, out_h, out_w, filter_h, filter_w)
    strides = (s0, s1, s2 * stride, s3 * stride, s2, s3)
    cols = xp.lib.stride_tricks.as_strided(input_padded, shape=shape, strides=strides)

    # Rearrange dimensions so that each patch becomes a row
    cols = cols.transpose(0, 2, 3, 1, 4, 5).reshape(N * out_h * out_w, -1)
    return cols


def col2im(cols, input_shape, filter_h, filter_w, stride=1, pad=0, xp=np):
    """
    Converts column representation back into image blocks.
    Input:
      - col: 2D array from im2col with shape (N*out_h*out_w, C*filter_h*filter_w)
      - input_shape: shape (N, C, H, W) of the original input data
      - filter_h, filter_w: filter dimensions
      - stride, pad: convolution parameters. If pad is an int, symmetric padding is assumed.
                   If pad is a tuple of tuples, it should be ((pad_top, pad_bottom), (pad_left, pad_right)).
      - xp: either np or cp
    Returns:
      - An array with shape (N, C, H, W)
    """
    N, C, H, W = input_shape

    # Determine padding values
    if isinstance(pad, int):
        pad_top = pad
        pad_bottom = pad
        pad_left = pad
        pad_right = pad
    else:
        (pad_top, pad_bottom), (pad_left, pad_right) = pad

    # Compute output dimensions from im2col
    out_h = (H + pad_top + pad_bottom - filter_h) // stride + 1
    out_w = (W + pad_left + pad_right - filter_w) // stride + 1

    # Reshape cols to (N, out_h, out_w, C, filter_h, filter_w)
    cols_reshaped = cols.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)

    # Prepare an output array with padding
    H_padded = H + pad_top + pad_bottom
    W_padded = W + pad_left + pad_right
    img_padded = xp.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)

    # Instead of looping over the entire image, we only loop over the filter dimensions.
    for y in range(filter_h):
        y_end = y + stride * out_h
        for x in range(filter_w):
            # Accumulate the values from cols_reshaped into the appropriate region of img_padded.
            img_padded[:, :, y:y_end:stride, x:x + stride * out_w] += cols_reshaped[:, :, y, x, :, :]

    # Remove padding and return the original image dimensions.
    return img_padded[:, :, pad_top:H_padded - pad_bottom, pad_left:W_padded - pad_right]


# store functions used for processing data

def train_test_split(x, y, split=0.2):
    """
    returns x and y data split into training and testing sets according to split percentage passed
    Input:
        x: input data
        y: output data
    Return:
        x_train, y_train, x_test, y_test
    """
    
    split_index = int(np.floor(len(y)*split))
    x_train = x[split_index:]
    y_train = y[split_index:]
    x_test = x[:split_index]
    y_test = y[:split_index]
    
    return x_train, y_train, x_test, y_test

def build_metric_figure(metric_data, layers, num_batches_per_epoch=None):
    """
    Builds a figure with:
      - Top row split into two subplots:
          * Left: Loss/CXE curves vs. batch
          * Right: Accuracy/Precision curves vs. batch
        (batch numbering starts at 1, so 1..N)
      - Bottom row (merged columns): Contour plot for the last Dense layer (weights)
        and last Softmax layer (outputs).
      - Optional secondary x-axis on the top of the left subplot to show epochs
        if num_batches_per_epoch is provided.

    Parameters:
      metric_data: dict containing recorded training metrics.
      layers: list of network layers.
      num_batches_per_epoch: integer, used to create an epoch x-axis on the top of the loss subplot.

    Returns:
      fig: Matplotlib figure object.
    """
    # Create a figure with 2 rows, 2 columns. Top row: loss (left), accuracy (right). Bottom row: contour.
    fig = plt.figure(constrained_layout=True, figsize=(12, 8))
    gs = gridspec.GridSpec(nrows=2, ncols=2, figure=fig)

    # Subplots
    ax_loss = fig.add_subplot(gs[0, 0])     # Left top: Loss
    ax_acc = fig.add_subplot(gs[0, 1])      # Right top: Accuracy
    ax_contour = fig.add_subplot(gs[1, :])  # Bottom row merges columns

    # 1) Separate the metrics: plot Loss/CXE on ax_loss, Accuracy/Precision on ax_acc
    for key, values in metric_data.items():
        # Shift x-values by +1 so the first batch is labeled 1, second is 2, etc.
        xvals = np.arange(len(values)) + 1
        yvals = to_numpy(values)

        # Check which subplot to use
        if "Loss" in key or "CXE" in key:
            ax_loss.plot(xvals, yvals, label=key)
        elif "Accuracy" in key or "Precision" in key:
            ax_acc.plot(xvals, yvals, label=key)

    ax_loss.set_title("Loss Metrics")
    ax_loss.set_xlabel("Batch")
    ax_loss.legend()

    ax_acc.set_title("Accuracy Metrics")
    ax_acc.set_xlabel("Batch")
    ax_acc.legend()

    # 2) Optional secondary x-axis for epochs on the loss subplot
    #    If you want the last batch to align with epoch=1.0, then for x=4 => 4/4=1.0
    #    (assuming 4 total batches per epoch).
    if num_batches_per_epoch is not None:
        def batch_to_epoch(x):
            return x / num_batches_per_epoch
        def epoch_to_batch(x):
            return x * num_batches_per_epoch
        secax_loss = ax_loss.secondary_xaxis('top', functions=(batch_to_epoch, epoch_to_batch))
        secax_loss.set_xlabel("Epoch")
        secax_acc = ax_acc.secondary_xaxis('top', functions=(batch_to_epoch, epoch_to_batch))
        secax_acc.set_xlabel("Epoch")

    # 3) Figure out which loss array to use for the vertical axis in the contour plot.
    #    If you prefer "Train Total Loss" or "Train Sparse CXE" or something else, adapt here.
    if "Train Total Loss" in metric_data and len(metric_data["Train Total Loss"]) > 0:
        loss_key = "Train Total Loss"
    elif "Train Sparse CXE" in metric_data and len(metric_data["Train Sparse CXE"]) > 0:
        loss_key = "Train Sparse CXE"
    else:
        loss_key = None

    # Convert that chosen loss array to NumPy, or leave it None if not found
    if loss_key is not None:
        loss_values = np.array(to_numpy(metric_data[loss_key]))
    else:
        loss_values = None

    # 4) Filter layers: last Dense with 2D weights, last Softmax
    dense_layers = [lyr for lyr in layers if hasattr(lyr, 'weights') and lyr.weights.ndim == 2]
    softmax_layers = [lyr for lyr in layers if lyr.name.lower().startswith('softmax')]
    layers_to_plot = []
    if dense_layers:
        layers_to_plot.append(dense_layers[-1])
    if softmax_layers:
        layers_to_plot.append(softmax_layers[-1])

    # 5) Contour plot for each selected layer in ax_contour
    for layer in layers_to_plot:
        if loss_values is None or len(loss_values) < 2:
            continue  # Not enough data to form a 2D contour

        # Dense layer case
        if hasattr(layer, 'weights') and layer.weights.ndim == 2:
            data_series = metric_data.get(layer.name, [])
            weight_series = []
            for entry in to_numpy(data_series):
                # If it's [weights, bias], we only want weights
                if isinstance(entry, (list, tuple)) and len(entry) > 0:
                    w_matrix = entry[0]  # shape: (in_dim, out_dim)
                    # For a 2D contour, we want a 2D array Z => shape (num_batches, something).
                    # We'll average across axis=1 to get shape (in_dim,) per batch
                    w_vector = np.mean(w_matrix, axis=1)
                    weight_series.append(w_vector)
                else:
                    # fallback if entry is just weights
                    w_vector = np.mean(entry, axis=1)
                    weight_series.append(w_vector)

            evolution = np.array(weight_series)  # shape => (num_batches, in_dim)
            # Align with the length of loss_values if needed
            min_len = min(evolution.shape[0], loss_values.shape[0])
            evolution = evolution[:min_len, :]
            cur_loss = loss_values[:min_len]

            # We now create a meshgrid: x => weight index, y => loss
            # So X = shape (num_batches, in_dim) or reversed
            # We typically do X: 0..(in_dim-1), Y: cur_loss
            # => shape: (min_len, in_dim)
            if evolution.shape[0] < 2 or evolution.shape[1] < 2:
                continue  # contourf needs at least a 2x2 array

            X, Y = np.meshgrid(np.arange(evolution.shape[1]), cur_loss)
            Z = evolution  # shape: (min_len, in_dim)
            cont = ax_contour.contourf(X, Y, Z, levels=50, cmap='viridis')
            fig.colorbar(cont, ax=ax_contour)
            ax_contour.set_title(f"Weight Evolution for {layer.name}")
            ax_contour.set_xlabel("Weight Index")
            ax_contour.set_ylabel("Loss")

    return fig


# def animate(network, metrics, plot1, plot2, plot_loss, plot_accuracy, plot_learning_rate):
#     plt.cla()
    
#     for l in network.layers:
#         plot1.imshow(l.weights, cmap="seismic", aspect='auto')
#         plot2.imshow(np.expand_dims(l.bias, axis=1).T, cmap="seismic", aspect='auto')
        
#     # plot metric data
#     # plot loss    
#     # check if total loss exists in metric data (means network applies regularization)
#     if 'Total Loss' in network.metric_data:
#         plot_loss.plot(metrics['Total Loss'][:,0], label='total train', color='red', lw=1)
#         plot_loss.plot(metrics['Total Loss'][:,1], label='total validation', color='red', lw=1, alpha=0.5)
#         # plot regularizations if exist
#         if 'L2 Regularization' in network.metric_data:
#             plot_loss.plot(metrics['L2 Regularization'][:,0], label='L2 train', color='orange', lw=1)
#             plot_loss.plot(metrics['L2 Regularization'][:,1], label='L2 validation', color='orange', lw=1, alpha=0.5)
#         if 'L1 Regularization' in network.metric_data:
#             plot_loss.plot(metrics['L1 Regularization'][:,0], label='L1 train', color='purple', lw=1)
#             plot_loss.plot(metrics['L1 Regularization'][:,1], label='L1 validation', color='purple', lw=1, alpha=0.5)
#     plot_loss.plot(metrics['Sparse CXE'][:,0], label='loss train', color='blue', lw=1)
#     plot_loss.plot(metrics['Sparse CXE'][:,1], label='loss validation', color='blue', lw=1, alpha=0.5)
    
#     # plot accuracy
#     plot_accuracy.plot(metrics['Accuracy'][:,0], label='train', color='green', linewidth=1)
#     plot_accuracy.plot(metrics['Accuracy'][:,1], label='validation', color='green', alpha=0.3, linewidth=1)
    
#     # plot learning rate
#     plot_learning_rate.plot(metrics['Learning Rate'][:,0], label='train', color='red', linewidth=1)

def get_confusion_matrix(data:tuple, model:"Neural_Network"):
    """
    returns a confusion matrix generated from predictions made on images passed through an image data generator

    INPUTS
    data: tuple, tuple of (x,y)
    model: Neural_Network, model used to make predictions on images

    RETURNS
    cm: confusion matrix
    """
    print('Generating Confusion Matrix')
    # Unpack data tuple
    x,targets = data
    predictions = model.predict(x)
    predictions = model._xp.argmax(predictions, axis=1)
    # If device = GPU, convert arrays to NumPy using .get()
    if hasattr(predictions, "get"):
        predictions = predictions.get()
    if hasattr(targets, "get"):
        targets = targets.get()
    # targets = model._xp.argmax(y, axis=1)
    cm = confusion_matrix(targets, predictions)
    return cm

def plot_confusion_matrix(confusion_matrix, classes, normalize = False, title = 'Confusion Matrix', cmap = plt.cm.Blues):
    # Convert classes to a sequence by using range
    classes = np.arange(classes)
    if normalize:
        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]
        print('Normalized Confusion Matrix')
    else:
        print('Confusion Matrix, without normalization')
    print(confusion_matrix)

    plt.figure(figsize=(10,6))
    plt.imshow(confusion_matrix, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = classes
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = confusion_matrix.max() / 2.
    for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):
        plt.text(j, i, format(confusion_matrix[i, j], fmt),
                 horizontalalignment='center',
                 color='white' if confusion_matrix[i, j] > thresh else 'black')
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

def get_accuracy_from_confusion_matrix(confusion_matrix):
    return confusion_matrix.trace() / confusion_matrix.sum()

def to_tf_tensor(x, model):
    # Convert x to a TensorFlow tensor
    # If using GPU (i.e. x is a cupy array), convert to a numpy array first.
    if model._device == "GPU":
        x_np = model._xp.asnumpy(x)
    else:
        x_np = x
    return convert_to_tensor(x_np)

def from_tf_tensor(x, model):
    # Convert a TensorFlow tensor back to the model's array type (numpy or cupy)
    x_np = x.numpy()
    if model._device == "GPU":
        return model._xp.asarray(x_np)
    else:
        return x_np
    
def to_numpy(x):
    # Convert to numpy array if cupy array else return original
    # If x is a list, tuple, or dict, function will parse recursively to convert each item
    if isinstance(x, list):
        return [to_numpy(i) for i in x]
    elif isinstance(x, tuple):
        return tuple(to_numpy(i) for i in x)
    elif isinstance(x, dict):
        return {k: to_numpy(v) for k, v in x.items()}
    else:
        return x.get() if hasattr(x, "get") else x