# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f_gWhHibpUXe_i2PQWKtQdtPuaBR9bLw
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.animation as animation
from sklearn.metrics import confusion_matrix
import itertools
from glob import glob

def im2col(input_data, filter_h, filter_w, stride=1, pad=0, xp=np):
    """
    Rearranges image blocks into columns.
    Input:
      - input_data: shape (N, C, H, W)
      - filter_h, filter_w: filter height and width
      - stride: stride for the convolution
      - pad: amount of zero-padding
      - xp: either np (CPU) or cp (GPU)
    Returns:
      - col: 2D array of shape (N*out_h*out_w, C*filter_h*filter_w)
    """
    # N, C, H, W = input_data.shape

    # # Determine padding for height and width
    # if isinstance(pad, int):
    #     # Use symmetric padding if pad is an int
    #     pad_h = (pad, pad)
    #     pad_w = (pad, pad)
    # else:
    #     # Assume pad is a tuple of tuples: ((pad_top, pad_bottom), (pad_left, pad_right))
    #     pad_h, pad_w = pad

    # # Pad the input
    # img = xp.pad(input_data, ((0, 0), (0, 0), pad_h, pad_w), mode='constant')

    # # Compute the output dimensions using the new padding amounts:
    # out_h = (H + sum(pad_h) - filter_h) // stride + 1
    # out_w = (W + sum(pad_w) - filter_w) // stride + 1
    
    # # Prepare a container for the patches
    # col = xp.empty((N, C, filter_h, filter_w, out_h, out_w), dtype=input_data.dtype)
    
    # for y in range(filter_h):
    #     y_max = y + stride * out_h
    #     for x in range(filter_w):
    #         x_max = x + stride * out_w
    #         col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]
    
    # # Rearrange so that each patch becomes a row
    # col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)
    # return col

    N, C, H, W = input_data.shape

    # Determine padding values
    if isinstance(pad, int):
        pad_top = pad
        pad_bottom = pad
        pad_left = pad
        pad_right = pad
    else:
        # Expect pad to be ((pad_top, pad_bottom), (pad_left, pad_right))
        (pad_top, pad_bottom), (pad_left, pad_right) = pad

    # Pad the input
    input_padded = xp.pad(input_data, ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')

    # Compute output dimensions
    out_h = (H + pad_top + pad_bottom - filter_h) // stride + 1
    out_w = (W + pad_left + pad_right - filter_w) // stride + 1

    # Get strides for the padded array
    s0, s1, s2, s3 = input_padded.strides

    # Build shape and strides for as_strided
    shape = (N, C, out_h, out_w, filter_h, filter_w)
    strides = (s0, s1, s2 * stride, s3 * stride, s2, s3)
    cols = xp.lib.stride_tricks.as_strided(input_padded, shape=shape, strides=strides)

    # Rearrange dimensions so that each patch becomes a row
    cols = cols.transpose(0, 2, 3, 1, 4, 5).reshape(N * out_h * out_w, -1)
    return cols


def col2im(cols, input_shape, filter_h, filter_w, stride=1, pad=0, xp=np):
    """
    Converts column representation back into image blocks.
    Input:
      - col: 2D array from im2col with shape (N*out_h*out_w, C*filter_h*filter_w)
      - input_shape: shape (N, C, H, W) of the original input data
      - filter_h, filter_w: filter dimensions
      - stride, pad: convolution parameters. If pad is an int, symmetric padding is assumed.
                   If pad is a tuple of tuples, it should be ((pad_top, pad_bottom), (pad_left, pad_right)).
      - xp: either np or cp
    Returns:
      - An array with shape (N, C, H, W)
    """
    # N, C, H, W = input_shape

    # # Determine padding for height and width.
    # if isinstance(pad, int):
    #     pad_h = (pad, pad)
    #     pad_w = (pad, pad)
    # else:
    #     # Assume pad is a tuple of tuples: ((pad_top, pad_bottom), (pad_left, pad_right))
    #     pad_h, pad_w = pad

    # # Compute the output (padded) dimensions.
    # out_h = (H + sum(pad_h) - filter_h) // stride + 1
    # out_w = (W + sum(pad_w) - filter_w) // stride + 1

    # # Reshape col into shape (N, out_h, out_w, C, filter_h, filter_w)
    # # Then transpose to bring channels to the correct place.
    # col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)

    # # Instantiate an array for the padded image.
    # padded_H = H + sum(pad_h) + stride - 1
    # padded_W = W + sum(pad_w) + stride - 1
    # img = xp.zeros((N, C, padded_H, padded_W), dtype=col.dtype)

    # # Add up the contributions from col into the zeros array.
    # for y in range(filter_h):
    #     y_max = y + stride * out_h
    #     for x in range(filter_w):
    #         x_max = x + stride * out_w
    #         img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]

    # # Remove the padding.
    # # Here we use pad_h[0] for the top and pad_w[0] for the left.
    # return img[:, :, pad_h[0]:H + pad_h[0], pad_w[0]:W + pad_w[0]]

    N, C, H, W = input_shape

    # Determine padding values
    if isinstance(pad, int):
        pad_top = pad
        pad_bottom = pad
        pad_left = pad
        pad_right = pad
    else:
        (pad_top, pad_bottom), (pad_left, pad_right) = pad

    # Compute output dimensions from im2col
    out_h = (H + pad_top + pad_bottom - filter_h) // stride + 1
    out_w = (W + pad_left + pad_right - filter_w) // stride + 1

    # Reshape cols to (N, out_h, out_w, C, filter_h, filter_w)
    cols_reshaped = cols.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)

    # Prepare an output array with padding
    H_padded = H + pad_top + pad_bottom
    W_padded = W + pad_left + pad_right
    img_padded = xp.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)

    # Instead of looping over the entire image, we only loop over the filter dimensions.
    for y in range(filter_h):
        y_end = y + stride * out_h
        for x in range(filter_w):
            # Accumulate the values from cols_reshaped into the appropriate region of img_padded.
            img_padded[:, :, y:y_end:stride, x:x + stride * out_w] += cols_reshaped[:, :, y, x, :, :]

    # Remove padding and return the original image dimensions.
    return img_padded[:, :, pad_top:H_padded - pad_bottom, pad_left:W_padded - pad_right]


# store functions used for processing data

def train_test_split(x, y, split=0.2):
    """
    returns x and y data split into training and testing sets according to split percentage passed
    Input:
        x: input data
        y: output data
    Return:
        x_train, y_train, x_test, y_test
    """
    
    split_index = int(np.floor(len(y)*split))
    x_train = x[split_index:]
    y_train = y[split_index:]
    x_test = x[:split_index]
    y_test = y[:split_index]
    
    return x_train, y_train, x_test, y_test

def build_metric_figure(layers):
    fig = plt.figure(tight_layout=True)
    grid = fig.add_gridspec(1,3)
    wb_grid = grid[0,0:2].subgridspec(nrows=int(np.ceil(len(layers)/2)), ncols=2)
    metric_grid = grid[0,2].subgridspec(3,1)

    for index, l in enumerate(layers):
        subgrid = wb_grid[int(np.floor(index/2)),index%2].subgridspec(3,1)
        plot1 = fig.add_subplot(subgrid[0:2,0])
        plot1.axes.yaxis.set_ticks(np.arange(l.weights.shape[0]))
        plot1.axes.xaxis.set_visible(False)
        plot1.grid(False)
        plot1.set_title(f'Layer {index}')

        plot2 = fig.add_subplot(subgrid[2,0], sharex=plot1)
        plot2.axes.yaxis.set_visible(False)
        plot2.axes.xaxis.set_ticks(np.arange(l.weights.shape[1]))
        plot2.grid(False)      

    plot_loss = fig.add_subplot(metric_grid[0,0])
    plot_loss.axes.xaxis.set_visible(False)
    plot_loss.set_title('Loss')
    plot_loss.legend()

    plot_accuracy = fig.add_subplot(metric_grid[1,0])
    plot_accuracy.axes.xaxis.set_visible(False)
    plot_accuracy.set_title('Accuracy')
    plot_accuracy.legend()

    plot_learning_rate = fig.add_subplot(metric_grid[2,0])
    plot_learning_rate.set_title('Learning Rate')
    
    return fig

def animate(i, layers, metrics):
    plt.cla()
    
    for index, l in enumerate(layers):
        plot1.imshow(l.weights, cmap="seismic", aspect='auto')
        plot2.imshow(np.expand_dims(l.bias, axis=1).T, cmap="seismic", aspect='auto')
        
    # plot metric data
    # plot loss    
    # check if total loss exists in metric data (means network applies regularization)
    if 'Total Loss' in network.metric_data:
        plot_loss.plot(metrics['Total Loss'][:,0], label='total train', color='red', lw=1)
        plot_loss.plot(metrics['Total Loss'][:,1], label='total validation', color='red', lw=1, alpha=0.5)
        # plot regularizations if exist
        if 'L2 Regularization' in network.metric_data:
            plot_loss.plot(metrics['L2 Regularization'][:,0], label='L2 train', color='orange', lw=1)
            plot_loss.plot(metrics['L2 Regularization'][:,1], label='L2 validation', color='orange', lw=1, alpha=0.5)
        if 'L1 Regularization' in network.metric_data:
            plot_loss.plot(metrics['L1 Regularization'][:,0], label='L1 train', color='purple', lw=1)
            plot_loss.plot(metrics['L1 Regularization'][:,1], label='L1 validation', color='purple', lw=1, alpha=0.5)
    plot_loss.plot(metrics['Sparse CXE'][:,0], label='loss train', color='blue', lw=1)
    plot_loss.plot(metrics['Sparse CXE'][:,1], label='loss validation', color='blue', lw=1, alpha=0.5)
    
    # plot accuracy
    plot_accuracy.plot(metrics['Accuracy'][:,0], label='train', color='green', linewidth=1)
    plot_accuracy.plot(metrics['Accuracy'][:,1], label='validation', color='green', alpha=0.3, linewidth=1)
    
    # plot learning rate
    plot_learning_rate.plot(metrics['Learning Rate'][:,0], label='train', color='red', linewidth=1)

def get_confusion_matrix_from_generator(generator, data_path, model, num_images=None, image_size=(100,100)):
    """
    returns a confusion matrix generated from predictions made on images passed through an image data generator

    INPUTS
    generator: generator instance
    data_path: string, path to images to be passed through generator
    model: Model, model used to make predictions on images
    num_images: int, default=None, number of images to make predictions on. if None, will default to len(data_path)
    image_size: tuple (int, int), default=(100,100), size to scale images to

    RETURNS
    cm: confusion matrix
    """
    if num_images == None:
        # images = glob(validation_path + '/*/*.jp*g')
        num_images = len(glob(data_path + '/*/*.jp*g'))
    print('Generating Confusion Matrix', num_images)
    predictions = []
    targets= []
    i = 0
    n_images = 0
    for x, y in generator.flow_from_directory(
        data_path,
        target_size = image_size,
        shuffle = False):
        i += 1
        n_images += len(y)
        if i % 50 == 0:
            print(f'{n_images} images processed.')
        p = model.predict(x)
        p = np.argmax(p, axis=1)
        y = np.argmax(y, axis=1)
        predictions = np.concatenate((predictions, p))
        targets = np.concatenate((targets, y))
        if len(targets) >= num_images:
            break    
    cm = confusion_matrix(targets, predictions)
    return cm

def plot_confusion_matrix(confusion_matrix, classes, normalize = False, title = 'Confusion Matrix', cmap = plt.cm.Blues):
    if normalize:
        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]
        print('Normalized Confusion Matrix')
    else:
        print('Confusion Matrix, wihtout normalization')
    print(confusion_matrix)

    plt.figure(figsize=(15,15))
    plt.imshow(confusion_matrix, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = confusion_matrix.max() / 2.
    for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):
        plt.text(j, i, format(confusion_matrix[i, j], fmt),
                 horizontalalignment='center',
                 color='white' if confusion_matrix[i, j] > thresh else 'black')
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

def get_accuracy_from_confusion_matrix(confusion_matrix):
    return confusion_matrix.trace() / confusion_matrix.sum()