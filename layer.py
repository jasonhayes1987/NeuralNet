# -*- coding: utf-8 -*-
"""layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N3Cyi7maf8zlqt5IT1dZ5d3lwVIshFlP
"""

import numpy as np
from scipy import signal
import cupy as cp
from cupyx.scipy import signal as c_signal

# base layer class

class Layer:
    def __init__(self, device=None):
        self._device = device
        if self._device == 'CPU':
            self._xp = np
        elif self._device == 'GPU':
            self._xp = cp
        self.input = None
        self.output = None
        self._input_dims = None
        self._output_dims = None

    def forward(self, input, is_training=True):
      # computes output 'Y' of layer given input 'X'
      raise NotImplementedError("Must override 'forward' by instantiating child of layer class (Activation, Dense, Convolutional, etc...")

    def backward(self, output_gradient, learning_rate):
      # computes derivative of input 'X' of layer given output error 'dE/dY'
      raise NotImplementedError("Must override 'backward' by instantiating child of layer class (Activation, Dense, Convolutional, etc...")

    
# class for Activation layers
# inherits from layer
class Activation(Layer):
    def __init__(self, activation, input_dims=None, device=None):
        super().__init__(device)
        self.activation = activation
        self.name = 'Activation'
        self._input_dims = input_dims
        self._output_dims = input_dims

    def compute(self):
        raise NotImplementedError("Must override 'compute' by instantiating child of Activation class (Relu, Tanh, Sigmoid, etc...")

    def derivative(self):
        raise NotImplementedError("Must override 'derivative' by instantiating child of Activation class (Relu, Tanh, Sigmoid, etc...")

    def forward(self, input, is_training=True):
        # computes and returns output by passing input through activation function
        self.input = input
        # self.output = self.activation.compute() # v1
        self.output = self.compute()
        return self.output

    def backward(self, output_gradient, optimizer):
        # computes and returns the gradient of the error with respect to the activation (dE/df'[X])
        # output = np.multiply(output_gradient, self.activation.derivative()) # v1
        output = np.multiply(output_gradient, self.derivative())
        return output


# class for Dense layers
# inherits from layer
class Dense(Layer):
    
    def __init__(self, output_size, L1_regularizer=0, L2_regularizer=0, input_dims=None, device=None):
        super().__init__(device)
        self.name = 'Dense'
        self._input_dims = input_dims
        self._output_dims = output_size
        self.weights = self._xp.random.randn(self._input_dims, self._output_dims)
        self.bias = self._xp.random.randn(self._output_dims)
        
        self.L1_regularizer = L1_regularizer
        self.L2_regularizer = L2_regularizer
    

    def forward(self, input, is_training=True):
        # computes output of layer given input
        self.input = input
        self.output = self._xp.dot(self.input, self.weights) + self.bias
        return self.output


    def backward(self, output_gradient, optimizer):
        # calculates gradients of weights 'dE/dW', and input 'dE/dX' with respect to error
        self.output_gradient = output_gradient
        self.weight_gradient = self._xp.dot(self.input.T, output_gradient)
        self.bias_gradient = self._xp.sum(self.output_gradient, axis=0)
    
        # add in gradients of regularization wrt weights and bias if regularizers > 0
    
        # for L1 Regularization
        if self.L1_regularizer >= 0:
            # update weight gradient
            L1_weight_gradient = self._xp.ones_like(self.weights)
            L1_weight_gradient[self.weights<0] = -1
            self.weight_gradient += self.L1_regularizer * L1_weight_gradient

            # update bias gradient
            L1_bias_gradient = self._xp.ones_like(self.bias)
            L1_bias_gradient[self.bias<0] = -1
            self.bias_gradient += self.L1_regularizer * L1_bias_gradient

        # for L2 Regularization
        if self.L2_regularizer >= 0:
            # update weight gradient
            self.weight_gradient += 2 * (self.L2_regularizer * self.weights)

            # update bias gradient
            self.bias_gradient += 2 * (self.L2_regularizer * self.bias)


        input_gradient = self._xp.dot(output_gradient, self.weights.T)

        # update weights and bias
        self.weights, self.bias = optimizer.update_params(self)

        # return input_gradient to be used as output_gradient of previous layer
        return input_gradient


    def get_parameters(self):
        return self.weights, self.bias
    
    def set_parameters(self, weights, bias):
        self.weights = weights
        self.bias = bias
    
    @staticmethod
    def set_input_size(previous_layer):
        """
        Sets the input size of the layer using previous layers output size
        """
        # check to make sure previous layer shape is 2D
        if len(previous_layer.output.shape == 2):
            return previous_layer.output.shape[1] # return second dimension of previous layer output
        else:
            # Throw ERROR that dense required 2D input data
            print(f'Dense layer requires 2D data as input; passed {len(previous_layer.output.shape)}D')
        

# class for Dropout Layers
# inherits from Layer
class Dropout(Layer):
    
    def __init__(self, dropout_rate, input_dims=None, output_size=None, device=None):
        super().__init__(device)
        self.name = 'Dropout'
        self.keep_rate = 1 - dropout_rate
        self._input_dims = input_dims
        self._output_dims = output_size
        
    def forward(self, input, is_training=True):
        self.input = input
        
        # skip dropout and just output previous layers output if model is being evaluated
        if not is_training:
            self.output = self.input.copy()
            return self.output
        
        self.mask = self._xp.random.binomial(1, self.keep_rate, input.shape) / self.keep_rate
        self.output = input * self.mask
        return self.output
    
    def backward(self, output_gradient, optimizer):
        self.output_gradient = output_gradient
        return self.output_gradient * self.mask
    
# Class for Convolutional layers
# inherits from Layer
class Convolutional(Layer):
    """
    Layer for performing convolution on input data using (depth) amount of kernels of size (kernel_size)
    
    INPUT:
    input_shape: tuple; (input_depth, input_height, input_width); dimensions of each input; input_depth = number of layers in zed dimension
    kernel_size = int; height and width of kernel matrix (always square)
    depth: int; number of kernels
    """
    def __init__(self, kernel_size, depth, mode, input_dims=None, device=None):
        super().__init__(device)
        self.name = 'Convolutional'
        _input_depth, _input_height, _input_width = input_dims
        self._depth = depth
        self._input_dims = input_dims
        self._input_depth = _input_depth
        self._kernels_shape = (self._depth, self._input_depth, kernel_size, kernel_size)
        self.kernels = self._xp.random.randn(*self._kernels_shape)
        self.mode = mode
        # determine output shape depending on 'mode'
        if self.mode == 'valid':
            self._output_dims = (self._depth, _input_height - kernel_size + 1, _input_width - kernel_size + 1)
        elif self.mode == 'same':
            self._output_dims = (self._depth, _input_height, _input_width)
        self.biases = self._xp.random.randn(*self._output_dims)
        
        
    def forward(self, input, is_training=True):
        self.input = input
        # print(f'conv forward input shape:{self.input.shape}')
        self.output = self._xp.zeros((input.shape[0], *self._output_dims))  
        self.output += self._xp.repeat(self.biases[self._xp.newaxis, :, :, :], self.input.shape[0], axis=0)
        # print(f'conv forward output shape:{self.output.shape}')
        for n in range(self.input.shape[0]):
            for i in range(self._depth):
                # print(f'i:{i}')
                for j in range(self._input_depth):
                    # print(f'j:{j}')
                    if self._device == 'CPU':
                        # Correct indexing for output
                        self.output[n, i, :, :] += signal.correlate2d(self.input[n, j], self.kernels[i, j], mode=self.mode) 
                    elif self._device == 'GPU':
                        self.output[n, i, :, :] += c_signal.correlate2d(self.input[n, j], self.kernels[i, j], mode=self.mode) 
        
        return self.output


    def backward(self, output_gradient, optimizer):
        self.output_gradient = output_gradient
        self.kernels_gradient = self._xp.zeros(self._kernels_shape)
        input_gradient = self._xp.zeros(self.input.shape)
        
        # compute kernel and input gradients
        for n in range(self.input.shape[0]):
            for i in range(self._depth):
                for j in range(self._input_depth):
                    if self._device == 'CPU':
                        self.kernels_gradient[i,j] = signal.correlate2d(self.input[n,j], self.output_gradient[n,i], mode='valid')
                        input_gradient[n,j] += signal.convolve2d(self.output_gradient[n,i], self.kernels[i,j], mode='full')
                    elif self._device == 'GPU':
                        self.kernels_gradient[i,j] = c_signal.correlate2d(self.input[n,j], self.output_gradient[n,i], mode='valid')
                        input_gradient[n,j] += c_signal.convolve2d(self.output_gradient[n,i], self.kernels[i,j], mode='full')
                        
                
        # update kernels and biases
        self.kernels -= optimizer.learning_rate * self.kernels_gradient
        self.biases -= optimizer.learning_rate * self._xp.sum(self.output_gradient, axis=0)
        
        return input_gradient

    
    def get_parameters(self):
        return self.kernels, self.biases


    def set_parameters(self, weights, bias):
        if weights.shape == self._kernels_shape:
            self.kernels = weights
        else:
            print("weights don't match kernel shape")

        if bias.shape == self._output_dims:
            self.biases = bias
        else:
            print("bias doesn't match bias shape")
    

# Class for flatten layer
class Flatten(Layer):
    """
    Class used for flattening the input to an NxD dimension going forward, and restoring data
    to it's previous shape when going backward (back-propogating)
    """
    
    def __init__(self, input_dims=None, device=None):
        super().__init__(device)
        self.name = 'Flatten'
        self._input_dims = input_dims
        self._output_dims = 1
        for i in self._input_dims:
            self._output_dims*=i
        
    def forward(self, input, is_training=True):
        self.input_shape = input.shape
        self.output_shape = (self.input_shape[0], self._output_dims)
        return self._xp.reshape(input, self.output_shape)
    
    def backward(self, output_gradient, optimizer):
        return self._xp.reshape(output_gradient, self.input_shape)
    
# Class for pooling layer
class Pool(Layer):
    
    def __init__(self, pool_size=2, stride=2, method='max', input_dims=None, device=None):
        super().__init__(device)
        self.name = 'Pool'
        self.pool_size = pool_size
        self.stride = stride
        self.method = method
        self._input_dims = input_dims
        _out_height = 1 + (self._input_dims[1] - self.pool_size) // self.stride
        _out_width = 1 + (self._input_dims[2] - self.pool_size) // self.stride
        self._output_dims = (self._input_dims[0], _out_height, _out_width)
        
    def forward(self, input, is_training=True):
        self.input = input
        
        # calculate output shape
        _out_shape = (self.input.shape[0], *self._output_dims)
        self.output = self._xp.zeros(_out_shape)
        
        # loop through the height and width of each channel of each input
        for height in range(self._output_dims[1]):
            for width in range(self._output_dims[2]):
                height_start = height * self.stride
                height_end = height_start + self.pool_size
                width_start = width * self.stride
                width_end = width_start + self.pool_size
                
                if self.method == 'max':
                    self.output[:,:,height,width] = self._xp.max(input[:,:,height_start:height_end,width_start:width_end],axis=(2,3))
                    
                elif self.method == 'average':
                    self.output[:,:,height,width] = self._xp.mean(input[:,:,height_start:height_end,width_start:width_end],axis=(2,3))
                    
        return self.output
    
    def backward(self, output_gradient, optimizer):
        self.output_gradient = output_gradient
        self.input_gradient = self._xp.zeros(self.input.shape)
        
        for n in range(self.output_gradient.shape[0]):
            for d in range(self.output_gradient.shape[1]):
                for height in range(self.output_gradient.shape[2]):
                    for width in range(self.output_gradient.shape[3]):
                        # set the start and end points for both height and width indices
                        height_start = height * self.stride
                        height_end = height_start + self.pool_size
                        width_start = width * self.stride
                        width_end = width_start + self.pool_size
                        
                        # find which index has the maximum value for each height by width range in self.input
                        height_idx, width_idx = self._xp.where(np.max(self.input[n,d,height_start:height_end,width_start:width_end]) == self.input[n,d,height_start:height_end,width_start:width_end])
                        height_idx, width_idx = height_idx[0], width_idx[0]
                        
                        # set the input gradient at position height_idx, width_idx to be equal to output gradient
                        # at position height,width (set output gradient to be at the position in the input gradient
                        # where the maximum was found)
                        self.input_gradient[n,d,height_start:height_end,width_start:width_end][height_idx,width_idx] = self.output_gradient[n,d,height,width]
                        
        return self.input_gradient

